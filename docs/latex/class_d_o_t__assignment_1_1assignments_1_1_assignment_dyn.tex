\hypertarget{class_d_o_t__assignment_1_1assignments_1_1_assignment_dyn}{}\section{D\+O\+T\+\_\+assignment.\+assignments.\+Assignment\+Dyn Class Reference}
\label{class_d_o_t__assignment_1_1assignments_1_1_assignment_dyn}\index{DOT\_assignment.assignments.AssignmentDyn@{DOT\_assignment.assignments.AssignmentDyn}}
Inheritance diagram for D\+O\+T\+\_\+assignment.\+assignments.\+Assignment\+Dyn\+:\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=2.000000cm]{class_d_o_t__assignment_1_1assignments_1_1_assignment_dyn}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def \mbox{\hyperlink{class_d_o_t__assignment_1_1assignments_1_1_assignment_dyn_a94b981f344570cba994c8f792d248c6c}{assignment}} (self, t, ref\+\_\+states, target\+\_\+states)
\end{DoxyCompactItemize}
\subsection*{Additional Inherited Members}


\subsection{Detailed Description}
\begin{DoxyVerb}Class representing dynamics-based assignment policy
\end{DoxyVerb}
 

\subsection{Member Function Documentation}
\mbox{\Hypertarget{class_d_o_t__assignment_1_1assignments_1_1_assignment_dyn_a94b981f344570cba994c8f792d248c6c}\label{class_d_o_t__assignment_1_1assignments_1_1_assignment_dyn_a94b981f344570cba994c8f792d248c6c}} 
\index{DOT\_assignment.assignments.AssignmentDyn@{DOT\_assignment.assignments.AssignmentDyn}!assignment@{assignment}}
\index{assignment@{assignment}!DOT\_assignment.assignments.AssignmentDyn@{DOT\_assignment.assignments.AssignmentDyn}}
\subsubsection{\texorpdfstring{assignment()}{assignment()}}
{\footnotesize\ttfamily def D\+O\+T\+\_\+assignment.\+assignments.\+Assignment\+Dyn.\+assignment (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{t,  }\item[{}]{ref\+\_\+states,  }\item[{}]{target\+\_\+states }\end{DoxyParamCaption})}

\begin{DoxyVerb}ref_states and target_states are lists of tuples
each tuple is (state <np.array>, agent/target <Agent>).

For the nearest neighbor EMD assignment, the information
about the Agent is unnecessary. However, for other distances
or other costs, this information should be extracted
from the agents.

Input:
- t:                    time
- ref_states:           list of tuples constructed as (state at time <np.array>, agent <Agent class>)
- target_states:        list of tuples constructed as (state at time <np.array>, target <Agent class>

Output:
- assignment:           numpy array which maps each column (agent index) to an integer representing target index
- cost:                 discrete optimal transport cost\end{DoxyVerb}
 

Reimplemented from \mbox{\hyperlink{class_d_o_t__assignment_1_1assignments_1_1_assignment}{D\+O\+T\+\_\+assignment.\+assignments.\+Assignment}}.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
D\+O\+T\+\_\+assignment/assignments.\+py\end{DoxyCompactItemize}
